# 时间序列预测
## 基本思路
1. 确定信号变量
- 单变量：ARMA->GARCH（自回归条件异方差模型）
- 多变量：VAR->MGARCH（多变量自回归条件异方差模型）

2. 平稳性检验
时间序列可以按照下面分类
- 白噪声（也是平稳序列的一种）：没有预测可能
- 平稳非白噪声序列：方差和均值都是常数，可以用AR，MA，ARIMA
- 非平稳序列：需要用差分将其转化成平稳序列，再用上面的方法  

首先需要对观测值序列进行平稳性检测，如果不平稳，则对其进行差分运算直到差分后的数据平稳；  
在数据平稳后则对其进行白噪声检验，白噪声是指零均值常方差的随机平稳序列；如果是平稳非白噪声序列就计算ACF（自相关系数）、PACF（偏自相关系数），进行ARMA等模型识别，对已识别好的模型，确定模型参数，最后应用预测并进行误差分析

### [平稳性检验](https://zhuanlan.zhihu.com/p/425664064)
1. 图形分析法  
可视化数据即绘制时间序列的折线图，看曲线是否围绕某一数值上下波动（判断均值是否稳定），看曲线上下波动幅度变化大不大（判断方差是否稳定），看曲线不同时间段波动的频率变化大不大（判断协方差是否稳定），以此来判断时间序列是否是平稳的。
![](https://pic2.zhimg.com/80/v2-524c2d531e48841c91b5705a11c8ea3d_720w.webp)
- 白噪声，曲线围绕0值上下波动，波动幅度前后、上下一致，为平稳序列。
- 随机游走，曲线无确定趋势，均值、方差波动较大，非平稳序列。
- GDP数据趋势上升，均值随时间增加，非平稳序列。
- GDP季节差分后数据，曲线大致在一条水平线上上下波动，波动幅度前后变化较小，可认为是平稳的。
2. 自相关系数  
计算ACF和PCF，有两个概念，截尾（单调递减，最后=0）和拖尾（单调递减趋近于0），如果两个都不满足的话就不是平稳序列
- 计算ACF  
已知原始数据X，滞后K，则得到两个序列A = X[0:-k], B=[k:-1]
    $$s^2(X)=\frac{1}{n}\sum_{i=1}^n(X_i-\bar X)(X_i-\bar X)$$
    $$r(1)=\frac{1}{n-k}\sum_{i=1}^{n-k}(A_i-\bar X)(B_i-\bar X)$$
    $$ACF=\frac{r(1)}{s^2(X)}$$
    自相关系数越小，则越接近平稳序列
- 方法表格
	| ACF | PCF | 方法 |
	| --- | --- | --- |
	| 截尾 | 拖尾 | MA |
	| 拖尾 | 截尾 | AR |
	| 拖尾 | 拖尾 | ARMA |
3. 其他假设检验方法
- DF
- ADF
- PP
- DF-GLS
- KPSS

### 差分处理
首先用差分将非平稳序列转化为平稳序列，然后再建立ARMA模型
- 1阶差分
$$y(t) = x(t)-x(t-1)$$
- 2阶差分
$$y(t) = (x(t)-x(t-1)) - (x(t-1)-x(t-2)) = x(t)-2x(t-1)+x(t-2)$$
### [白噪声检验](https://zhuanlan.zhihu.com/p/430365631)
#### 检验目的
平稳性检验完成之后，有这几种集中情况
1. 时间序列非平稳  
使用差分、对数变换、平滑、时序分解等平稳化方法将序列平稳化。
2. 时间序列非平稳，且未能使其平稳  
不要再留恋ARMA等要求序列平稳的预测及分析方法，有周期选择周期性预测方法，或者尽情探索VAE、ML等非平稳时间序列预测和分析方法。
3. 平稳性检验通过后还要做白噪声检验  
- 是白噪声，序列是完全随机的，过去的行为对未来的发展没有丝毫影响，故而没有必要再深入分析了。  
- 非白噪声，使用各种简单又不失准确的平稳时间序列预测模型进行预测。  
4. 检验残差  
白噪声检验除了可以用来检验原始信号，还可以用来检验预测和真值之间的残差是否符合白噪声假设。残差为白噪声，说明模型拟合的很好，残差部分为无法捕捉的纯随机数据。
#### 检验方法
1. 自相关图
白噪声完全无自相关性，除0阶自相关系数为1外，理想情况下延迟k阶的样本自相关系数均为0。实际上由于样本序列的有限性，延迟k阶自相关系数并不完全为0，只要在0值附近即认为无自相关性
2. Box-Pierce检验
3. Ljung-Box检验
***
## 传统与深度学习方法对比
![](https://pic4.zhimg.com/80/v2-adee11d50f8e7bd0ee617ff48835aa57_720w.webp)

## 传统方法
### 类型
1. AR模型（Auto-RegressiveModel）
    - 公式  
    $$y(t)=c+\sum_{i=1}^p\phi_iy(t-i)+\epsilon(t)$$
    其中$\epsilon(t)$是符合正态分布的噪声，即均值为0。c是初值。
    - 优点  
    自回归方法的优点是所需资料不多，可用自身变数数列来进行预测
    - 缺点  
但是这种方法受到一定的限制：
必须具有自相关，自相关系数$\phi_i$是关键。如果自相关系数(R)小于0.5，则不宜采用，否则预测结果极不准确  
自回归只能适用于预测与自身前期相关的经济现象，即受自身历史因素影响较大的经济现象，如矿的开采量，各种自然资源产量等；对于受社会因素影响较大的经济现象，不宜采用自回归，而应改采可纳入其他变数的向量自回归模型。

2. MA模型（ Moving Average Model）
    - 公式  
    $$y(t)=u+\epsilon(t)-\sum_{j=1}^q\theta_j\epsilon(t-j)$$
    其中$\epsilon(t)$是符合正态分布的噪声，即均值为0。u是前面y的均值

3. ARMA模型（Auto-Regressive Moving Average Model）  
其实就是前两个的结合
$$y(t)=\sum_{i=1}^p\phi_iy(t-i) + \sum_{j=1}^q\theta_je(t-j) + e(t) $$  

4. ARIMA（Auto-Regressive Integrated Moving Average Model）  
和ARMA的公式一模一样，就是需要先对数据进行差分处理使其变成平稳序列，但是数据处理ARMA应该也要做吧？
    - 公式
    $$y(t)=\sum_{i=1}^p\phi_iy(t-i) + \sum_{j=1}^q\theta_je(t-j) + e(t) $$

## 机器学习
### 特征处理
#### 特征预处理  
- 标准化：$$\frac{x-x_{min}}{x_{max}-x_{min}}$$
- 归一化：$$\frac{x-\bar x}{\sigma}$$ 常用归一化，因为如果最大值是异常值，标准化就会有问题
- STL 分解
#### 特征降维
- 低方差的特征可以去除
- 计算两列的相关性，高的话，选择其中一列即可，可以用Pearson Correlation Coefficient计算

### 常用方法
### 决策树
多个节点，每个节点是一个判断条件，最终得到一个输出
### XGBoost
两个决策树构成，依次推理
### 随机森林
每次从完整数据中取出一部分的数据来训练决策树，最终可以得到很多决策树，然后就叫随机森林，每次的推理结果是由所有决策树投票得出的
### SVM
本来是用来完成分类任务的，主要是确定一个超平面来对特征空间内的点进行分割来确定类型  
如果要用来完成回归任务，其实也是确定一个超平面，来尽可能得使得特征空间的所有点到该超平面的距离最小，即用这个超平面来拟合所有的数据，来得到模型
#### 回归方法
- 线性回归（Linear Regression）
- 逻辑回归（Logistic Regression）
- 多项式回归（Polynomial Regression）
- 逐步回归（Stepwise Regression）
- 岭回归（Ridge Regression）：加入L2正则化的线性回归
- 套索回归（Lasso Regression）
- 弹性回归（ElasticNet Regression

### 注意
- [概念漂移](https://zhuanlan.zhihu.com/p/406281023)  
    目标变量的统计特性随着时间的推移以不可预见的方式变化的现象，也就是每过一段时间序列的规律是会变化的，即拟合的目标模型是一个时变的模型
- 序列自相关性  
![](https://pic1.zhimg.com/80/v2-e4138f62b41a79d11fa0b61adbdc41f4_720w.webp)  
有时把测试集的真实值及预测值画出来对比一下，就会发现t时刻的预测值往往是t-1时刻的真实值，也就是模型倾向于把上一时刻的真实值作为下一时刻的预测值，是因为序列存在自相关性  
消除自相关性的办法就是进行差分运算，也就是我们可以将当前时刻与前一时刻的差值作为我们的回归目标。但是，在其他任务进行特征选择的时候，我们是会把目标变量相关性低的特征去掉，留下相关性强的特征
- 训练集和测试集的划分  
一般确定一个时间点，把之前的数据作为训练集，之后的数据作为测试集
- 时间序列分解（大概率不大靠谱）  
可以利用经验模式分解(empirical mode decomposition,EMD)等方法对非平稳信号进行分解，类似傅立叶变换，得到多个不同频率（不同时间尺度）的信号，类似的还有小波变换。

## 深度学习
### WaveNet
### DeepAR
### N-Beats
### NHints
### TFT

# 框架
- pytorch-forecasting
- Prophet
# 会议
- WWW
- NeurIPS
- KDD
- ICML
- IJCAI
- ICLR
- AAAI

# 论文
- 异常驾驶行为检测  
    基于递归图注意力网络的高速公路社会异常驾驶行为检测，展示了真实世界HighD交通数据集的性能 [paper](https://dl.acm.org/doi/abs/10.1145/3543507.3583452)
- 多变量时间序列预测  
    提出了Crossformer，该模型明确地利用跨维度依赖性进行多变量时间序列预测 [paper](https://openreview.net/forum?id=vSVLM2j9eie) [code](https://github.com/Thinklab-SJTU/Crossformer)


# 模型诊断
## 多元时间序列（Tsay的金融时间序列分析）
### 残差交叉相关性
### 多元混成统计
## 一元时间序列
### 残差分析
如果说模型得到的残差是一个白噪声序列（均值=0，方差为常数，序列不相关的序列），表现为均值为0的正态分布，则可以认为是一个好的模型
#### 判断是否为正态分布  
1. shapiro-wilk test  
计算得到W和P，当P > 0.05时，可以认为是符合正态分布，且W越接近1，越接近正态分布
2. 看直方图
#### 残差自相关分析
1. 计算在K>=2（滞后阶数）的情况下的ACF，如果他们都在正负两倍标准差之内，就可以认是不相关序列
2. Ljung–Box test
### 过拟合
可以在原有模型上新增一些参数，然后再训练，对比查看，如果
1. 新增的参数很接近0，表示新增参数用处不大
2. 共同参数与原始估计相比无显著改变，表示原本的参数够用了
可以认为原有模型存在一定过拟合
#### 对数似然之（越大越好）
#### AIC（越小越好）
 